---
- name: Установка и настройка containerd
  block:
    - name: Копирование rpm пакета containerd на сервер
      copy:
        src: "files/packages/containerd-2.1.4-alt1.x86_64.rpm"
        dest: /tmp/containerd.rpm
        owner: root
        group: root
        mode: '0644'
      become: yes

    - name: Установка containerd через apt-get
      shell: apt-get install -y /tmp/containerd.rpm
      become: yes

    - name: Очистка временного файла
      file:
        path: /tmp/containerd.rpm
        state: absent
      become: yes

    - name: Создание базового конфига containerd
      copy:
        content: |
          version = 2
          root = "/var/lib/containerd"
          state = "/run/containerd"
          [grpc]
            address = "/run/containerd/containerd.sock"
          [plugins]
            [plugins."io.containerd.grpc.v1.cri"]
              sandbox_image = "{{ registry_url }}/pause:3.9"
              [plugins."io.containerd.grpc.v1.cri".registry]
                [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
                  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."89.208.208.139:5000"]
                    endpoint = ["http://89.208.208.139:5000"]
                [plugins."io.containerd.grpc.v1.cri".registry.configs]
                  [plugins."io.containerd.grpc.v1.cri".registry.configs."89.208.208.139:5000".tls]
                    insecure_skip_verify = true
              [plugins."io.containerd.grpc.v1.cri".containerd]
                snapshotter = "overlayfs"
                [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                  runtime_type = "io.containerd.runc.v2"
                  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                    SystemdCgroup = true
        dest: /etc/containerd/config.toml
        owner: root
        group: root
        mode: '0644'
      become: yes

    - name: Включение и запуск containerd
      systemd:
        name: containerd
        state: started
        enabled: yes
        daemon_reload: yes
      become: yes

    - name: Ожидание готовности containerd
      wait_for:
        path: /var/run/containerd/containerd.sock
        state: present
        timeout: 30
      become: yes

    - name: Проверка работы containerd
      command: crictl version
      register: containerd_check
      changed_when: false
      failed_when: containerd_check.rc != 0

- name: Установка и настройка crictl
  block:
    - name: Копирование и распаковка crictl
      unarchive:
        src: "files/binares/crictl-v1.28.0-linux-amd64.tar.gz"
        dest: /usr/bin
        owner: root
        group: root
        mode: '0755'
        remote_src: no
      become: yes

    - name: Настройка конфига crictl
      copy:
        content: |
          runtime-endpoint: unix:///var/run/containerd/containerd.sock
          image-endpoint: unix:///var/run/containerd/containerd.sock
          timeout: 10
          debug: false
        dest: /etc/crictl.yaml
        owner: root
        group: root
        mode: '0644'
      become: yes

    - name: Проверка работы crictl
      command: crictl --version
      register: crictl_result
      changed_when: false

- name: Обновление apt cache
  shell: apt-get update
  become: yes

- name: Установка Kubernetes компонентов
  shell: |
    apt-get install -y \
      kubernetes1.28-client \
      kubernetes1.28-kubeadm \
      kubernetes1.28-kubelet \
      kubernetes1.28-master \
      kubernetes1.28-node \
      kubernetes1.28-common \
      kubernetes1.28-crio \
      python3-module-kubernetes-client \
      kube-vip
  become: yes

- name: Запуск и включение kubelet
  systemd:
    name: kubelet
    state: started
    enabled: yes
    daemon_reload: yes

- name: Создание конфигурации kubeadm для первого мастера
  template:
    src: kubeadm-config.yaml.j2
    dest: "/home/{{ k8s_user }}/kubeadm-config.yaml"
    owner: "{{ k8s_user }}"
    group: "{{ k8s_group }}"
    mode: 0644
  register: kubeadm_config
  when: inventory_hostname == "master-node-1"

- name: Предварительная настройка для etcd
  block:
    - name: Создание и настройка директории etcd
      file:
        path: /var/lib/etcd
        state: directory
        owner: root
        group: root
        mode: '0700'
      become: yes

    - name: Проверка свободных портов etcd
      shell: |
        ss -tlnp | grep ":2379" && echo "Port 2379 is occupied" || echo "Port 2379 is free"
        ss -tlnp | grep ":2380" && echo "Port 2380 is occupied" || echo "Port 2380 is free"
      register: port_check
      failed_when: false

    - name: Отображение проверки портов
      debug:
        var: port_check.stdout

    - name: Остановка kubelet перед инициализацией
      systemd:
        name: kubelet
        state: stopped
      become: yes

    - name: Очистка предыдущей конфигурации etcd
      shell: |
        rm -rf /var/lib/etcd/member || true
        rm -rf /etc/kubernetes/pki/etcd || true
      become: yes

    - name: Проверка сетевых интерфейсов
      shell: |
        ip addr show | grep "{{ master_ips[inventory_hostname] }}" || echo "IP address not found"
        ping -c 3 {{ master_ips[inventory_hostname] }} || echo "Ping failed"
      register: network_check
      failed_when: false

    - name: Отображение сетевой проверки
      debug:
        var: network_check.stdout
  when: inventory_hostname == "master-node-1"

- name: Инициализация кластера на первом мастере
  command: |
    kubeadm init \
      --config /home/{{ k8s_user }}/kubeadm-config.yaml \
      --upload-certs \
      --v=3 \
      --ignore-preflight-errors=all
  args:
    creates: /etc/kubernetes/admin.conf
  register: kubeadm_init
  when: inventory_hostname == "master-node-1"

- name: Отображение результатов инициализации
  debug:
    var: kubeadm_init
  when:
    - inventory_hostname == "master-node-1"
    - kubeadm_init is defined

- name: Запуск kubelet после инициализации
  systemd:
    name: kubelet
    state: started
  when: inventory_hostname == "master-node-1"

- name: Диагностика после инициализации
  block:
    - name: Ожидание создания манифеста etcd
      wait_for:
        path: /etc/kubernetes/manifests/etcd.yaml
        state: present
        timeout: 30

    - name: Проверка манифеста etcd
      command: cat /etc/kubernetes/manifests/etcd.yaml
      register: etcd_manifest

    - name: Отображение манифеста etcd
      debug:
        var: etcd_manifest.stdout

    - name: Ожидание запуска etcd контейнера
      shell: |
        timeout 120 bash -c 'until crictl ps --name etcd --state running 2>/dev/null | grep -q etcd; do echo "Waiting for etcd..."; sleep 10; done'
      register: etcd_wait
      failed_when: etcd_wait.rc != 0

    - name: Проверка статуса etcd
      command: crictl ps --name etcd
      register: etcd_status

    - name: Отображение статуса etcd
      debug:
        var: etcd_status.stdout

    - name: Получение логов etcd
      shell: |
        crictl logs $(crictl ps --name etcd -q) --tail=30
      register: etcd_logs

    - name: Отображение логов etcd
      debug:
        var: etcd_logs.stdout

    - name: Проверка готовности etcd
      shell: |
        timeout 30 crictl logs $(crictl ps --name etcd -q) | grep "ready to serve client requests" || echo "etcd not ready yet"
      register: etcd_ready_check
      failed_when: false

    - name: Отображение готовности etcd
      debug:
        var: etcd_ready_check.stdout
  when: inventory_hostname == "master-node-1"

- name: Ожидание инициализации первого мастера
  wait_for:
    path: /etc/kubernetes/admin.conf
    state: present
  when: inventory_hostname == "master-node-1"

- name: Настройка kubectl для первого мастера
  block:
    - name: Копирование конфигурации для пользователя
      copy:
        src: /etc/kubernetes/admin.conf
        dest: "{{ k8s_home }}/.kube/config"
        remote_src: yes
        owner: "{{ k8s_user }}"
        group: "{{ k8s_group }}"
        mode: 0600

    - name: Ожидание готовности Kubernetes API
      wait_for:
        host: "{{ cluster_vip }}"
        port: 6443
        delay: 10
        timeout: 300

    - name: Проверка готовности control-plane
      command: kubectl get nodes
      register: node_status
      until: node_status.rc == 0 and "master-node-1" in node_status.stdout and "Ready" in node_status.stdout
      retries: 30
      delay: 10

    - name: Получение команды join для control-plane
      command: kubeadm token create --print-join-command
      register: join_command
      changed_when: false
      retries: 5
      delay: 30

    - name: Получение certificate key
      command: kubeadm init phase upload-certs --upload-certs
      register: cert_key
      changed_when: false

    - name: Сохранение команд join
      copy:
        content: |
          Control Plane Join Command:
          kubeadm join {{ cluster_vip }}:6443 --token {{ join_command.stdout.split()[3] }} \
            --discovery-token-ca-cert-hash {{ join_command.stdout.split()[5] }} \
            --control-plane --certificate-key {{ cert_key.stdout.split()[3] }}

          Worker Join Command:
          kubeadm join {{ cluster_vip }}:6443 --token {{ join_command.stdout.split()[3] }} \
            --discovery-token-ca-cert-hash {{ join_command.stdout.split()[5] }}
        dest: "{{ k8s_home }}/k8s-join-commands.txt"
        owner: "{{ k8s_user }}"
        group: "{{ k8s_group }}"
        mode: 0600

    - name: Сохранение команд join в переменные
      set_fact:
        control_plane_join_command: "kubeadm join {{ cluster_vip }}:6443 --token {{ join_command.stdout.split()[3] }} --discovery-token-ca-cert-hash {{ join_command.stdout.split()[5] }} --control-plane --certificate-key {{ cert_key.stdout.split()[3] }}"
        worker_join_command: "kubeadm join {{ cluster_vip }}:6443 --token {{ join_command.stdout.split()[3] }} --discovery-token-ca-cert-hash {{ join_command.stdout.split()[5] }}"
  when: inventory_hostname == "master-node-1"

- name: Присоединение других мастер-узлов
  command: "{{ hostvars['master-node-1']['control_plane_join_command'] }}"
  when:
    - inventory_hostname != "master-node-1"
    - inventory_hostname in groups['masters']

- name: Настройка kubectl на других мастерах
  block:
    - name: Копирование конфигурации с первого мастера
      slurp:
        src: "{{ k8s_home }}/.kube/config"
      register: kubeconfig
      delegate_to: master-node-1

    - name: Запись конфигурации на текущий узел
      copy:
        content: "{{ kubeconfig.content | b64decode }}"
        dest: "{{ k8s_home }}/.kube/config"
        owner: "{{ k8s_user }}"
        group: "{{ k8s_group }}"
        mode: 0600
  when:
    - inventory_hostname != "master-node-1"
    - inventory_hostname in groups['masters']